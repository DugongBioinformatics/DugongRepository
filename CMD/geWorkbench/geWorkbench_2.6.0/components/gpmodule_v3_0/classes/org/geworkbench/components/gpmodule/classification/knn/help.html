<html>
<body>
<p class=MsoNormal style='mso-layout-grid-align:none;text-autospace:none'><span
style='font-family:Arial'>The K-Nearest Neighbor algorithm classifies a sample
by assigning it the label most frequently represented among the k nearest
samples. No explicit model for the probability density of the classes is
formed; each point is estimated locally from the surrounding points. Target
classes for prediction (classes 0 and 1) can be defined based on a phenotype
such as morphological class or treatment outcome. The class predictor is
uniquely defined by the initial set of samples and marker genes. The K-Nearest
Neighbor algorithm stores the training instances and uses a distance function
to determine which k members of the training set are closest to an unknown test
instance. Once the k-nearest training instances have been found, their class
assignments are used to predict the class for the test instance by a majority
vote. Our implementation of the K-Nearest Neighbor algorithm allows the votes
of the k neighbors to be un-weighted, weighted by the reciprocal of the rank of
the neighbor's distance (e.g., the closest neighbor is given weight 1/1, next
closest neighbor is given weight 1/2, etc.), or by the reciprocal of the
distance. Either the Cosine or Euclidean distance measures can be used. The
confidence is the proportion of votes for the winning class. There are many references
for this type of classifier (with several of the early important papers listed
below).<o:p></o:p></span></p>

<p class=MsoNormal style='mso-layout-grid-align:none;text-autospace:none'><b
style='mso-bidi-font-weight:normal'><span style='font-family:Arial'><o:p>&nbsp;</o:p></span></b></p>

<p class=MsoNormal style='mso-margin-top-alt:auto;mso-margin-bottom-alt:auto;
mso-layout-grid-align:none;text-autospace:none'><b style='mso-bidi-font-weight:
normal'><span style='font-family:Arial'>References</span></b><span
style='font-family:Arial'>:<u1:p></u1:p></span></p>

<ul type=disc>
 <li class=MsoNormal style='mso-margin-top-alt:auto;
     mso-margin-bottom-alt:auto;mso-list:l1 level1 lfo1;tab-stops:list .5in;
     mso-layout-grid-align:none;text-autospace:none'><span class=SpellE><span
     class=spelle><span style='font-family:Arial'>Golub</span></span></span><span
     style='font-family:Arial'> T.R., <span class=SpellE><span class=spelle><span
     style='font-family:Arial'>Slonim</span></span></span> D.K., et al.
     “Molecular Classification of Cancer: Class Discovery and Class Prediction by
     Gene Expression Monitoring,” Science, 531-537 (1999).<u1:p></u1:p></span></li>
 <li class=MsoNormal style='mso-margin-top-alt:auto;
     mso-margin-bottom-alt:auto;mso-list:l1 level1 lfo1;tab-stops:list .5in;
     mso-layout-grid-align:none;text-autospace:none'><span class=SpellE><span
     class=spelle><span style='font-family:Arial'>Slonim</span></span></span><span
     style='font-family:Arial'>, D.K., Tamayo, P., <span class=SpellE><span
     class=spelle><span style='font-family:Arial'>Mesirov</span></span></span>,
     J.P., <span class=SpellE><span class=spelle><span style='font-family:Arial'>Golub</span></span></span>,
     T.R., Lander, E.S. (2000) Class prediction and discovery using gene
     expression data. In Proceedings of the Fourth Annual International
     Conference on Computational Molecular Biology (RECOMB) 2000. ACM Press, <st1:place u2:st="on"><st1:State u2:st="on"><st1:place
     w:st="on"><st1:State w:st="on">New York</st1:State></st1:place></st1:State></st1:place>,
     pp. 263–272.<u1:p></u1:p></span></li>
 <li class=MsoNormal style='mso-margin-top-alt:auto;
     mso-margin-bottom-alt:auto;mso-list:l1 level1 lfo1;tab-stops:list .5in;
     mso-layout-grid-align:none;text-autospace:none'><span style='font-family:
     Arial'>Johns, M. V. (1961) <span class=GramE>An</span> empirical <span
     class=SpellE><span class=spelle><span style='font-family:Arial'>Bayes</span></span></span>
     approach to non-parametric two-way classification. In Solomon, H., editor,
     Studies in item analysis and prediction. <st1:City u2:st="on"><st1:City
     w:st="on">Palo Alto</st1:City></st1:City>, <st1:State u2:st="on"><st1:State
     w:st="on">CA</st1:State></st1:State>: <st1:place u2:st="on"><st1:PlaceName u2:st="on"><st1:place
     w:st="on"><st1:PlaceName w:st="on">Stanford</st1:PlaceName></st1:PlaceName>
      <st1:PlaceType u2:st="on"><st1:PlaceType w:st="on">University</st1:PlaceType></st1:place></st1:PlaceType></st1:place>
     Press.<u1:p></u1:p></span></li>
 <li class=MsoNormal style='mso-margin-top-alt:auto;
     mso-margin-bottom-alt:auto;mso-list:l1 level1 lfo1;tab-stops:list .5in;
     mso-layout-grid-align:none;text-autospace:none'><span style='font-family:
     Arial'>Cover, T. M. and Hart, P. E. (1967) Nearest neighbor pattern
     classification, IEEE Trans. Info. Theory, IT-13, 21-27, January 1967.<u1:p></u1:p></span></li>
</ul>

</body>

</html>
